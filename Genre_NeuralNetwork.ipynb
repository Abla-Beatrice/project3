{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pop', 'country', 'rap', 'hiphop', 'other', 'latin', 'house',\n",
       "       'folk', 'r&b', 'adult standards', 'rock', 'metal', 'show tunes',\n",
       "       'soul', 'jazz'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = pd.read_csv('data/audio_features_hot_100_1958_2019.csv')\n",
    "genre = pd.read_csv('data/songGenre.csv')[['track_id','supergenre']].rename(columns = {'songid':'SongID'})\n",
    "genre = genre.drop_duplicates()\n",
    "genre['supergenre'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270740.0</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.836</td>\n",
       "      <td>-4.803</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.01700</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215733.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-6.362</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.37100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215733.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-6.362</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.37100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196760.0</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.674</td>\n",
       "      <td>-4.169</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.05880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>228185.0</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.623</td>\n",
       "      <td>-5.725</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.00124</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spotify_track_duration_ms  danceability  energy  loudness  speechiness  \\\n",
       "0                   270740.0         0.734   0.836    -4.803       0.0735   \n",
       "2                   215733.0         0.572   0.385    -6.362       0.0308   \n",
       "3                   215733.0         0.572   0.385    -6.362       0.0308   \n",
       "4                   196760.0         0.542   0.674    -4.169       0.2100   \n",
       "5                   228185.0         0.948   0.623    -5.725       0.1680   \n",
       "\n",
       "   acousticness  instrumentalness  valence  \n",
       "0       0.01700          0.000016    0.623  \n",
       "2       0.37100          0.000000    0.323  \n",
       "3       0.37100          0.000000    0.323  \n",
       "4       0.05880          0.000000    0.667  \n",
       "5       0.00124          0.000001    0.856  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_df = genre.merge(audio, on = 'track_id', how = 'left').dropna(how='any')\n",
    "# target = join_df[['supergenre']]\n",
    "feature_names =['spotify_track_duration_ms','danceability','energy','loudness','speechiness','acousticness','instrumentalness','valence']\n",
    "features = join_df[feature_names]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df['target'] = join_df['supergenre'].replace('pop',float(0)).replace('country',float(1))\\\n",
    ".replace('hiphop',float(2)).replace('other',float(3)).replace('latin',float(3)).replace('latin',float(4))\\\n",
    ".replace('house',float(5)).replace('folk',float(6)).replace('r&b',float(7)).replace('adult standards',float(8))\\\n",
    ".replace('rock',float(9)).replace('metal',float(10)).replace('show tunes',float(11)).replace('soul',float(12))\\\n",
    ".replace('rap',float(13)).replace('jazz',float(14))\n",
    "\n",
    "target = join_df[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9035</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11009</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25491</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target\n",
       "9035      9.0\n",
       "11009     0.0\n",
       "7782      9.0\n",
       "9085      1.0\n",
       "25491     5.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=1)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=8))\n",
    "model.add(Dense(units=15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 15)                105       \n",
      "=================================================================\n",
      "Total params: 159\n",
      "Trainable params: 159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17670/17670 - 2s - loss: 2.2280 - acc: 0.2876\n",
      "Epoch 2/100\n",
      "17670/17670 - 1s - loss: 1.8640 - acc: 0.3663\n",
      "Epoch 3/100\n",
      "17670/17670 - 1s - loss: 1.7773 - acc: 0.3765\n",
      "Epoch 4/100\n",
      "17670/17670 - 2s - loss: 1.7413 - acc: 0.3801\n",
      "Epoch 5/100\n",
      "17670/17670 - 2s - loss: 1.7212 - acc: 0.3810\n",
      "Epoch 6/100\n",
      "17670/17670 - 2s - loss: 1.7083 - acc: 0.3824\n",
      "Epoch 7/100\n",
      "17670/17670 - 2s - loss: 1.6997 - acc: 0.3838\n",
      "Epoch 8/100\n",
      "17670/17670 - 1s - loss: 1.6937 - acc: 0.3857\n",
      "Epoch 9/100\n",
      "17670/17670 - 2s - loss: 1.6899 - acc: 0.3869\n",
      "Epoch 10/100\n",
      "17670/17670 - 2s - loss: 1.6871 - acc: 0.3871\n",
      "Epoch 11/100\n",
      "17670/17670 - 1s - loss: 1.6850 - acc: 0.3878\n",
      "Epoch 12/100\n",
      "17670/17670 - 1s - loss: 1.6830 - acc: 0.3881\n",
      "Epoch 13/100\n",
      "17670/17670 - 2s - loss: 1.6817 - acc: 0.3898\n",
      "Epoch 14/100\n",
      "17670/17670 - 2s - loss: 1.6805 - acc: 0.3891\n",
      "Epoch 15/100\n",
      "17670/17670 - 2s - loss: 1.6794 - acc: 0.3895\n",
      "Epoch 16/100\n",
      "17670/17670 - 2s - loss: 1.6787 - acc: 0.3911\n",
      "Epoch 17/100\n",
      "17670/17670 - 2s - loss: 1.6776 - acc: 0.3892\n",
      "Epoch 18/100\n",
      "17670/17670 - 2s - loss: 1.6768 - acc: 0.3901\n",
      "Epoch 19/100\n",
      "17670/17670 - 2s - loss: 1.6762 - acc: 0.3905\n",
      "Epoch 20/100\n",
      "17670/17670 - 1s - loss: 1.6751 - acc: 0.3914\n",
      "Epoch 21/100\n",
      "17670/17670 - 2s - loss: 1.6748 - acc: 0.3909\n",
      "Epoch 22/100\n",
      "17670/17670 - 2s - loss: 1.6743 - acc: 0.3912\n",
      "Epoch 23/100\n",
      "17670/17670 - 2s - loss: 1.6736 - acc: 0.3913\n",
      "Epoch 24/100\n",
      "17670/17670 - 2s - loss: 1.6731 - acc: 0.3912\n",
      "Epoch 25/100\n",
      "17670/17670 - 2s - loss: 1.6724 - acc: 0.3915\n",
      "Epoch 26/100\n",
      "17670/17670 - 2s - loss: 1.6720 - acc: 0.3924\n",
      "Epoch 27/100\n",
      "17670/17670 - 2s - loss: 1.6717 - acc: 0.3916\n",
      "Epoch 28/100\n",
      "17670/17670 - 2s - loss: 1.6712 - acc: 0.3919\n",
      "Epoch 29/100\n",
      "17670/17670 - 2s - loss: 1.6708 - acc: 0.3928\n",
      "Epoch 30/100\n",
      "17670/17670 - 2s - loss: 1.6706 - acc: 0.3939\n",
      "Epoch 31/100\n",
      "17670/17670 - 2s - loss: 1.6703 - acc: 0.3923\n",
      "Epoch 32/100\n",
      "17670/17670 - 2s - loss: 1.6700 - acc: 0.3908\n",
      "Epoch 33/100\n",
      "17670/17670 - 2s - loss: 1.6694 - acc: 0.3945\n",
      "Epoch 34/100\n",
      "17670/17670 - 2s - loss: 1.6694 - acc: 0.3926\n",
      "Epoch 35/100\n",
      "17670/17670 - 2s - loss: 1.6694 - acc: 0.3934\n",
      "Epoch 36/100\n",
      "17670/17670 - 3s - loss: 1.6691 - acc: 0.3923\n",
      "Epoch 37/100\n",
      "17670/17670 - 2s - loss: 1.6687 - acc: 0.3928\n",
      "Epoch 38/100\n",
      "17670/17670 - 2s - loss: 1.6682 - acc: 0.3926\n",
      "Epoch 39/100\n",
      "17670/17670 - 2s - loss: 1.6684 - acc: 0.3944\n",
      "Epoch 40/100\n",
      "17670/17670 - 2s - loss: 1.6680 - acc: 0.3946\n",
      "Epoch 41/100\n",
      "17670/17670 - 2s - loss: 1.6682 - acc: 0.3937\n",
      "Epoch 42/100\n",
      "17670/17670 - 2s - loss: 1.6678 - acc: 0.3937\n",
      "Epoch 43/100\n",
      "17670/17670 - 3s - loss: 1.6678 - acc: 0.3927\n",
      "Epoch 44/100\n",
      "17670/17670 - 2s - loss: 1.6674 - acc: 0.3930\n",
      "Epoch 45/100\n",
      "17670/17670 - 2s - loss: 1.6672 - acc: 0.3931\n",
      "Epoch 46/100\n",
      "17670/17670 - 2s - loss: 1.6672 - acc: 0.3932\n",
      "Epoch 47/100\n",
      "17670/17670 - 2s - loss: 1.6673 - acc: 0.3920\n",
      "Epoch 48/100\n",
      "17670/17670 - 2s - loss: 1.6668 - acc: 0.3940\n",
      "Epoch 49/100\n",
      "17670/17670 - 2s - loss: 1.6664 - acc: 0.3936\n",
      "Epoch 50/100\n",
      "17670/17670 - 2s - loss: 1.6665 - acc: 0.3944\n",
      "Epoch 51/100\n",
      "17670/17670 - 2s - loss: 1.6667 - acc: 0.3956\n",
      "Epoch 52/100\n",
      "17670/17670 - 2s - loss: 1.6663 - acc: 0.3945\n",
      "Epoch 53/100\n",
      "17670/17670 - 1s - loss: 1.6662 - acc: 0.3929\n",
      "Epoch 54/100\n",
      "17670/17670 - 2s - loss: 1.6663 - acc: 0.3938\n",
      "Epoch 55/100\n",
      "17670/17670 - 2s - loss: 1.6662 - acc: 0.3955\n",
      "Epoch 56/100\n",
      "17670/17670 - 2s - loss: 1.6660 - acc: 0.3950\n",
      "Epoch 57/100\n",
      "17670/17670 - 2s - loss: 1.6657 - acc: 0.3959\n",
      "Epoch 58/100\n",
      "17670/17670 - 2s - loss: 1.6656 - acc: 0.3947\n",
      "Epoch 59/100\n",
      "17670/17670 - 1s - loss: 1.6654 - acc: 0.3941\n",
      "Epoch 60/100\n",
      "17670/17670 - 1s - loss: 1.6654 - acc: 0.3949\n",
      "Epoch 61/100\n",
      "17670/17670 - 1s - loss: 1.6651 - acc: 0.3951\n",
      "Epoch 62/100\n",
      "17670/17670 - 1s - loss: 1.6650 - acc: 0.3955\n",
      "Epoch 63/100\n",
      "17670/17670 - 1s - loss: 1.6649 - acc: 0.3950\n",
      "Epoch 64/100\n",
      "17670/17670 - 1s - loss: 1.6645 - acc: 0.3952\n",
      "Epoch 65/100\n",
      "17670/17670 - 1s - loss: 1.6646 - acc: 0.3940\n",
      "Epoch 66/100\n",
      "17670/17670 - 2s - loss: 1.6647 - acc: 0.3946\n",
      "Epoch 67/100\n",
      "17670/17670 - 2s - loss: 1.6645 - acc: 0.3962\n",
      "Epoch 68/100\n",
      "17670/17670 - 1s - loss: 1.6646 - acc: 0.3945\n",
      "Epoch 69/100\n",
      "17670/17670 - 1s - loss: 1.6642 - acc: 0.3965\n",
      "Epoch 70/100\n",
      "17670/17670 - 1s - loss: 1.6641 - acc: 0.3968\n",
      "Epoch 71/100\n",
      "17670/17670 - 1s - loss: 1.6640 - acc: 0.3965\n",
      "Epoch 72/100\n",
      "17670/17670 - 1s - loss: 1.6638 - acc: 0.3938\n",
      "Epoch 73/100\n",
      "17670/17670 - 1s - loss: 1.6636 - acc: 0.3947\n",
      "Epoch 74/100\n",
      "17670/17670 - 1s - loss: 1.6638 - acc: 0.3968\n",
      "Epoch 75/100\n",
      "17670/17670 - 1s - loss: 1.6637 - acc: 0.3976\n",
      "Epoch 76/100\n",
      "17670/17670 - 2s - loss: 1.6637 - acc: 0.3976\n",
      "Epoch 77/100\n",
      "17670/17670 - 2s - loss: 1.6636 - acc: 0.3968\n",
      "Epoch 78/100\n",
      "17670/17670 - 2s - loss: 1.6633 - acc: 0.3954\n",
      "Epoch 79/100\n",
      "17670/17670 - 2s - loss: 1.6632 - acc: 0.3955\n",
      "Epoch 80/100\n",
      "17670/17670 - 3s - loss: 1.6633 - acc: 0.3968\n",
      "Epoch 81/100\n",
      "17670/17670 - 3s - loss: 1.6629 - acc: 0.3950\n",
      "Epoch 82/100\n",
      "17670/17670 - 2s - loss: 1.6629 - acc: 0.3966\n",
      "Epoch 83/100\n",
      "17670/17670 - 2s - loss: 1.6627 - acc: 0.3945\n",
      "Epoch 84/100\n",
      "17670/17670 - 2s - loss: 1.6627 - acc: 0.3959\n",
      "Epoch 85/100\n",
      "17670/17670 - 2s - loss: 1.6628 - acc: 0.3964\n",
      "Epoch 86/100\n",
      "17670/17670 - 2s - loss: 1.6628 - acc: 0.3967\n",
      "Epoch 87/100\n",
      "17670/17670 - 2s - loss: 1.6624 - acc: 0.3974\n",
      "Epoch 88/100\n",
      "17670/17670 - 4s - loss: 1.6625 - acc: 0.3965\n",
      "Epoch 89/100\n",
      "17670/17670 - 3s - loss: 1.6624 - acc: 0.3960\n",
      "Epoch 90/100\n",
      "17670/17670 - 2s - loss: 1.6624 - acc: 0.3982\n",
      "Epoch 91/100\n",
      "17670/17670 - 2s - loss: 1.6622 - acc: 0.3972\n",
      "Epoch 92/100\n",
      "17670/17670 - 2s - loss: 1.6623 - acc: 0.3956\n",
      "Epoch 93/100\n",
      "17670/17670 - 2s - loss: 1.6621 - acc: 0.3962\n",
      "Epoch 94/100\n",
      "17670/17670 - 2s - loss: 1.6620 - acc: 0.3974\n",
      "Epoch 95/100\n",
      "17670/17670 - 1s - loss: 1.6620 - acc: 0.3965\n",
      "Epoch 96/100\n",
      "17670/17670 - 2s - loss: 1.6621 - acc: 0.3964\n",
      "Epoch 97/100\n",
      "17670/17670 - 2s - loss: 1.6618 - acc: 0.3967\n",
      "Epoch 98/100\n",
      "17670/17670 - 2s - loss: 1.6617 - acc: 0.3985\n",
      "Epoch 99/100\n",
      "17670/17670 - 1s - loss: 1.6616 - acc: 0.3959\n",
      "Epoch 100/100\n",
      "17670/17670 - 1s - loss: 1.6618 - acc: 0.3950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d726231cc8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4075: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=20, activation='selu', input_dim=8)) #selu vs relu?\n",
    "deep_model.add(Dense(units=25, activation='selu'))\n",
    "deep_model.add(Dense(units=25, activation='selu'))\n",
    "deep_model.add(Dense(units=15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                525       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                390       \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17670/17670 - 2s - loss: 1.8805 - acc: 0.3516\n",
      "Epoch 2/100\n",
      "17670/17670 - 2s - loss: 1.7015 - acc: 0.3790\n",
      "Epoch 3/100\n",
      "17670/17670 - 2s - loss: 1.6814 - acc: 0.3895\n",
      "Epoch 4/100\n",
      "17670/17670 - 2s - loss: 1.6674 - acc: 0.3913\n",
      "Epoch 5/100\n",
      "17670/17670 - 2s - loss: 1.6564 - acc: 0.3960\n",
      "Epoch 6/100\n",
      "17670/17670 - 2s - loss: 1.6494 - acc: 0.3993\n",
      "Epoch 7/100\n",
      "17670/17670 - 3s - loss: 1.6430 - acc: 0.3993\n",
      "Epoch 8/100\n",
      "17670/17670 - 2s - loss: 1.6376 - acc: 0.4016\n",
      "Epoch 9/100\n",
      "17670/17670 - 2s - loss: 1.6348 - acc: 0.4035\n",
      "Epoch 10/100\n",
      "17670/17670 - 2s - loss: 1.6293 - acc: 0.4065\n",
      "Epoch 11/100\n",
      "17670/17670 - 2s - loss: 1.6278 - acc: 0.4054\n",
      "Epoch 12/100\n",
      "17670/17670 - 2s - loss: 1.6227 - acc: 0.4090\n",
      "Epoch 13/100\n",
      "17670/17670 - 2s - loss: 1.6185 - acc: 0.4109\n",
      "Epoch 14/100\n",
      "17670/17670 - 2s - loss: 1.6183 - acc: 0.4105\n",
      "Epoch 15/100\n",
      "17670/17670 - 2s - loss: 1.6147 - acc: 0.4145\n",
      "Epoch 16/100\n",
      "17670/17670 - 2s - loss: 1.6122 - acc: 0.4098\n",
      "Epoch 17/100\n",
      "17670/17670 - 2s - loss: 1.6106 - acc: 0.4132\n",
      "Epoch 18/100\n",
      "17670/17670 - 2s - loss: 1.6074 - acc: 0.4126\n",
      "Epoch 19/100\n",
      "17670/17670 - 2s - loss: 1.6070 - acc: 0.4132\n",
      "Epoch 20/100\n",
      "17670/17670 - 2s - loss: 1.6060 - acc: 0.4118\n",
      "Epoch 21/100\n",
      "17670/17670 - 2s - loss: 1.6044 - acc: 0.4144\n",
      "Epoch 22/100\n",
      "17670/17670 - 2s - loss: 1.6031 - acc: 0.4154\n",
      "Epoch 23/100\n",
      "17670/17670 - 2s - loss: 1.6013 - acc: 0.4135\n",
      "Epoch 24/100\n",
      "17670/17670 - 2s - loss: 1.6003 - acc: 0.4169\n",
      "Epoch 25/100\n",
      "17670/17670 - 2s - loss: 1.6009 - acc: 0.4140\n",
      "Epoch 26/100\n",
      "17670/17670 - 2s - loss: 1.5973 - acc: 0.4191\n",
      "Epoch 27/100\n",
      "17670/17670 - 2s - loss: 1.5972 - acc: 0.4154\n",
      "Epoch 28/100\n",
      "17670/17670 - 2s - loss: 1.5962 - acc: 0.4156\n",
      "Epoch 29/100\n",
      "17670/17670 - 2s - loss: 1.5948 - acc: 0.4168\n",
      "Epoch 30/100\n",
      "17670/17670 - 2s - loss: 1.5947 - acc: 0.4176\n",
      "Epoch 31/100\n",
      "17670/17670 - 3s - loss: 1.5921 - acc: 0.4173\n",
      "Epoch 32/100\n",
      "17670/17670 - 3s - loss: 1.5924 - acc: 0.4199\n",
      "Epoch 33/100\n",
      "17670/17670 - 2s - loss: 1.5899 - acc: 0.4165\n",
      "Epoch 34/100\n",
      "17670/17670 - 2s - loss: 1.5911 - acc: 0.4205\n",
      "Epoch 35/100\n",
      "17670/17670 - 2s - loss: 1.5892 - acc: 0.4185\n",
      "Epoch 36/100\n",
      "17670/17670 - 3s - loss: 1.5875 - acc: 0.4196\n",
      "Epoch 37/100\n",
      "17670/17670 - 2s - loss: 1.5877 - acc: 0.4204\n",
      "Epoch 38/100\n",
      "17670/17670 - 2s - loss: 1.5872 - acc: 0.4204\n",
      "Epoch 39/100\n",
      "17670/17670 - 2s - loss: 1.5882 - acc: 0.4216\n",
      "Epoch 40/100\n",
      "17670/17670 - 2s - loss: 1.5862 - acc: 0.4214\n",
      "Epoch 41/100\n",
      "17670/17670 - 3s - loss: 1.5861 - acc: 0.4181\n",
      "Epoch 42/100\n",
      "17670/17670 - 2s - loss: 1.5847 - acc: 0.4210\n",
      "Epoch 43/100\n",
      "17670/17670 - 2s - loss: 1.5842 - acc: 0.4223\n",
      "Epoch 44/100\n",
      "17670/17670 - 4s - loss: 1.5853 - acc: 0.4232\n",
      "Epoch 45/100\n",
      "17670/17670 - 3s - loss: 1.5835 - acc: 0.4207\n",
      "Epoch 46/100\n",
      "17670/17670 - 3s - loss: 1.5826 - acc: 0.4224\n",
      "Epoch 47/100\n",
      "17670/17670 - 3s - loss: 1.5828 - acc: 0.4207\n",
      "Epoch 48/100\n",
      "17670/17670 - 3s - loss: 1.5820 - acc: 0.4186\n",
      "Epoch 49/100\n",
      "17670/17670 - 3s - loss: 1.5822 - acc: 0.4228\n",
      "Epoch 50/100\n",
      "17670/17670 - 4s - loss: 1.5824 - acc: 0.4202\n",
      "Epoch 51/100\n",
      "17670/17670 - 3s - loss: 1.5811 - acc: 0.4204\n",
      "Epoch 52/100\n",
      "17670/17670 - 3s - loss: 1.5789 - acc: 0.4225\n",
      "Epoch 53/100\n",
      "17670/17670 - 2s - loss: 1.5812 - acc: 0.4241\n",
      "Epoch 54/100\n",
      "17670/17670 - 2s - loss: 1.5789 - acc: 0.4220\n",
      "Epoch 55/100\n",
      "17670/17670 - 2s - loss: 1.5792 - acc: 0.4214\n",
      "Epoch 56/100\n",
      "17670/17670 - 3s - loss: 1.5788 - acc: 0.4224\n",
      "Epoch 57/100\n",
      "17670/17670 - 3s - loss: 1.5764 - acc: 0.4235\n",
      "Epoch 58/100\n",
      "17670/17670 - 2s - loss: 1.5783 - acc: 0.4198\n",
      "Epoch 59/100\n",
      "17670/17670 - 3s - loss: 1.5770 - acc: 0.4224\n",
      "Epoch 60/100\n",
      "17670/17670 - 2s - loss: 1.5767 - acc: 0.4235\n",
      "Epoch 61/100\n",
      "17670/17670 - 2s - loss: 1.5764 - acc: 0.4242\n",
      "Epoch 62/100\n",
      "17670/17670 - 2s - loss: 1.5767 - acc: 0.4244\n",
      "Epoch 63/100\n",
      "17670/17670 - 2s - loss: 1.5756 - acc: 0.4225\n",
      "Epoch 64/100\n",
      "17670/17670 - 2s - loss: 1.5749 - acc: 0.4198\n",
      "Epoch 65/100\n",
      "17670/17670 - 3s - loss: 1.5750 - acc: 0.4232\n",
      "Epoch 66/100\n",
      "17670/17670 - 3s - loss: 1.5745 - acc: 0.4241\n",
      "Epoch 67/100\n",
      "17670/17670 - 4s - loss: 1.5734 - acc: 0.4229\n",
      "Epoch 68/100\n",
      "17670/17670 - 3s - loss: 1.5740 - acc: 0.4239\n",
      "Epoch 69/100\n",
      "17670/17670 - 3s - loss: 1.5722 - acc: 0.4255\n",
      "Epoch 70/100\n",
      "17670/17670 - 2s - loss: 1.5727 - acc: 0.4246\n",
      "Epoch 71/100\n",
      "17670/17670 - 2s - loss: 1.5722 - acc: 0.4233\n",
      "Epoch 72/100\n",
      "17670/17670 - 2s - loss: 1.5723 - acc: 0.4226\n",
      "Epoch 73/100\n",
      "17670/17670 - 2s - loss: 1.5713 - acc: 0.4250\n",
      "Epoch 74/100\n",
      "17670/17670 - 2s - loss: 1.5708 - acc: 0.4268\n",
      "Epoch 75/100\n",
      "17670/17670 - 3s - loss: 1.5711 - acc: 0.4257\n",
      "Epoch 76/100\n",
      "17670/17670 - 2s - loss: 1.5705 - acc: 0.4252\n",
      "Epoch 77/100\n",
      "17670/17670 - 2s - loss: 1.5703 - acc: 0.4251\n",
      "Epoch 78/100\n",
      "17670/17670 - 2s - loss: 1.5700 - acc: 0.4231\n",
      "Epoch 79/100\n",
      "17670/17670 - 2s - loss: 1.5686 - acc: 0.4254\n",
      "Epoch 80/100\n",
      "17670/17670 - 2s - loss: 1.5701 - acc: 0.4265\n",
      "Epoch 81/100\n",
      "17670/17670 - 2s - loss: 1.5692 - acc: 0.4268\n",
      "Epoch 82/100\n",
      "17670/17670 - 2s - loss: 1.5664 - acc: 0.4254\n",
      "Epoch 83/100\n",
      "17670/17670 - 2s - loss: 1.5690 - acc: 0.4256\n",
      "Epoch 84/100\n",
      "17670/17670 - 2s - loss: 1.5670 - acc: 0.4266\n",
      "Epoch 85/100\n",
      "17670/17670 - 2s - loss: 1.5665 - acc: 0.4273\n",
      "Epoch 86/100\n",
      "17670/17670 - 2s - loss: 1.5666 - acc: 0.4264\n",
      "Epoch 87/100\n",
      "17670/17670 - 2s - loss: 1.5674 - acc: 0.4239\n",
      "Epoch 88/100\n",
      "17670/17670 - 2s - loss: 1.5661 - acc: 0.4261\n",
      "Epoch 89/100\n",
      "17670/17670 - 2s - loss: 1.5664 - acc: 0.4268\n",
      "Epoch 90/100\n",
      "17670/17670 - 2s - loss: 1.5663 - acc: 0.4251\n",
      "Epoch 91/100\n",
      "17670/17670 - 2s - loss: 1.5665 - acc: 0.4235\n",
      "Epoch 92/100\n",
      "17670/17670 - 2s - loss: 1.5636 - acc: 0.4283\n",
      "Epoch 93/100\n",
      "17670/17670 - 2s - loss: 1.5640 - acc: 0.4277\n",
      "Epoch 94/100\n",
      "17670/17670 - 2s - loss: 1.5642 - acc: 0.4263\n",
      "Epoch 95/100\n",
      "17670/17670 - 2s - loss: 1.5647 - acc: 0.4273\n",
      "Epoch 96/100\n",
      "17670/17670 - 2s - loss: 1.5644 - acc: 0.4269\n",
      "Epoch 97/100\n",
      "17670/17670 - 2s - loss: 1.5651 - acc: 0.4278\n",
      "Epoch 98/100\n",
      "17670/17670 - 2s - loss: 1.5643 - acc: 0.4267\n",
      "Epoch 99/100\n",
      "17670/17670 - 2s - loss: 1.5640 - acc: 0.4256\n",
      "Epoch 100/100\n",
      "17670/17670 - 2s - loss: 1.5627 - acc: 0.4280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d726617648>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
