{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pop', 'country', 'rap', 'hiphop', 'other', 'latin', 'house',\n",
       "       'folk', 'r&b', 'adult standards', 'rock', 'metal', 'show tunes',\n",
       "       'soul', 'jazz'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = pd.read_csv('data/audio_features_hot_100_1958_2019.csv')\n",
    "genre = pd.read_csv('data/songGenre.csv')[['track_id','supergenre']].rename(columns = {'songid':'SongID'})\n",
    "genre = genre.drop_duplicates()\n",
    "genre['supergenre'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270740.0</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.836</td>\n",
       "      <td>-4.803</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.01700</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215733.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-6.362</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.37100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215733.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-6.362</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.37100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196760.0</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.674</td>\n",
       "      <td>-4.169</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.05880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>228185.0</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.623</td>\n",
       "      <td>-5.725</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.00124</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spotify_track_duration_ms  danceability  energy  loudness  speechiness  \\\n",
       "0                   270740.0         0.734   0.836    -4.803       0.0735   \n",
       "2                   215733.0         0.572   0.385    -6.362       0.0308   \n",
       "3                   215733.0         0.572   0.385    -6.362       0.0308   \n",
       "4                   196760.0         0.542   0.674    -4.169       0.2100   \n",
       "5                   228185.0         0.948   0.623    -5.725       0.1680   \n",
       "\n",
       "   acousticness  instrumentalness  valence  \n",
       "0       0.01700          0.000016    0.623  \n",
       "2       0.37100          0.000000    0.323  \n",
       "3       0.37100          0.000000    0.323  \n",
       "4       0.05880          0.000000    0.667  \n",
       "5       0.00124          0.000001    0.856  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_df = genre.merge(audio, on = 'track_id', how = 'left').dropna(how='any')\n",
    "# target = join_df[['supergenre']]\n",
    "feature_names =['spotify_track_duration_ms','danceability','energy','loudness','speechiness','acousticness','instrumentalness','valence']\n",
    "features = join_df[feature_names]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df['target'] = join_df['supergenre'].replace('pop',float(0)).replace('country',float(1))\\\n",
    ".replace('hiphop',float(2)).replace('other',float(3)).replace('latin',float(3)).replace('latin',float(4))\\\n",
    ".replace('house',float(5)).replace('folk',float(6)).replace('r&b',float(7)).replace('adult standards',float(8))\\\n",
    ".replace('rock',float(9)).replace('metal',float(10)).replace('show tunes',float(11)).replace('soul',float(12))\\\n",
    ".replace('rap',float(13)).replace('jazz',float(14))\n",
    "\n",
    "target = join_df[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9035</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11009</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25491</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target\n",
       "9035      9.0\n",
       "11009     0.0\n",
       "7782      9.0\n",
       "9085      1.0\n",
       "25491     5.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=1)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=8))\n",
    "model.add(Dense(units=15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 15)                105       \n",
      "=================================================================\n",
      "Total params: 159\n",
      "Trainable params: 159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17670/17670 - 1s - loss: 1.6683 - acc: 0.3962\n",
      "Epoch 2/100\n",
      "17670/17670 - 1s - loss: 1.6683 - acc: 0.3962\n",
      "Epoch 3/100\n",
      "17670/17670 - 1s - loss: 1.6679 - acc: 0.3935\n",
      "Epoch 4/100\n",
      "17670/17670 - 1s - loss: 1.6680 - acc: 0.3949\n",
      "Epoch 5/100\n",
      "17670/17670 - 1s - loss: 1.6677 - acc: 0.3959\n",
      "Epoch 6/100\n",
      "17670/17670 - 1s - loss: 1.6678 - acc: 0.3947\n",
      "Epoch 7/100\n",
      "17670/17670 - 2s - loss: 1.6678 - acc: 0.3956\n",
      "Epoch 8/100\n",
      "17670/17670 - 2s - loss: 1.6680 - acc: 0.3963\n",
      "Epoch 9/100\n",
      "17670/17670 - 2s - loss: 1.6679 - acc: 0.3960\n",
      "Epoch 10/100\n",
      "17670/17670 - 1s - loss: 1.6678 - acc: 0.3956\n",
      "Epoch 11/100\n",
      "17670/17670 - 2s - loss: 1.6674 - acc: 0.3967\n",
      "Epoch 12/100\n",
      "17670/17670 - 2s - loss: 1.6676 - acc: 0.3967\n",
      "Epoch 13/100\n",
      "17670/17670 - 2s - loss: 1.6675 - acc: 0.3965\n",
      "Epoch 14/100\n",
      "17670/17670 - 2s - loss: 1.6674 - acc: 0.3969\n",
      "Epoch 15/100\n",
      "17670/17670 - 1s - loss: 1.6674 - acc: 0.3962\n",
      "Epoch 16/100\n",
      "17670/17670 - 2s - loss: 1.6671 - acc: 0.3975\n",
      "Epoch 17/100\n",
      "17670/17670 - 2s - loss: 1.6675 - acc: 0.3975\n",
      "Epoch 18/100\n",
      "17670/17670 - 1s - loss: 1.6673 - acc: 0.3966\n",
      "Epoch 19/100\n",
      "17670/17670 - 1s - loss: 1.6673 - acc: 0.3964\n",
      "Epoch 20/100\n",
      "17670/17670 - 1s - loss: 1.6673 - acc: 0.3976\n",
      "Epoch 21/100\n",
      "17670/17670 - 1s - loss: 1.6671 - acc: 0.3959\n",
      "Epoch 22/100\n",
      "17670/17670 - 1s - loss: 1.6671 - acc: 0.3963\n",
      "Epoch 23/100\n",
      "17670/17670 - 1s - loss: 1.6670 - acc: 0.3972\n",
      "Epoch 24/100\n",
      "17670/17670 - 1s - loss: 1.6668 - acc: 0.3975\n",
      "Epoch 25/100\n",
      "17670/17670 - 1s - loss: 1.6670 - acc: 0.3981\n",
      "Epoch 26/100\n",
      "17670/17670 - 1s - loss: 1.6672 - acc: 0.3962\n",
      "Epoch 27/100\n",
      "17670/17670 - 1s - loss: 1.6669 - acc: 0.3975\n",
      "Epoch 28/100\n",
      "17670/17670 - 1s - loss: 1.6667 - acc: 0.3963\n",
      "Epoch 29/100\n",
      "17670/17670 - 1s - loss: 1.6668 - acc: 0.3964\n",
      "Epoch 30/100\n",
      "17670/17670 - 1s - loss: 1.6669 - acc: 0.3975\n",
      "Epoch 31/100\n",
      "17670/17670 - 1s - loss: 1.6665 - acc: 0.3966\n",
      "Epoch 32/100\n",
      "17670/17670 - 1s - loss: 1.6669 - acc: 0.3967\n",
      "Epoch 33/100\n",
      "17670/17670 - 1s - loss: 1.6662 - acc: 0.3982\n",
      "Epoch 34/100\n",
      "17670/17670 - 1s - loss: 1.6664 - acc: 0.3960\n",
      "Epoch 35/100\n",
      "17670/17670 - 1s - loss: 1.6663 - acc: 0.3968\n",
      "Epoch 36/100\n",
      "17670/17670 - 1s - loss: 1.6664 - acc: 0.3965\n",
      "Epoch 37/100\n",
      "17670/17670 - 1s - loss: 1.6665 - acc: 0.3964\n",
      "Epoch 38/100\n",
      "17670/17670 - 1s - loss: 1.6660 - acc: 0.3958\n",
      "Epoch 39/100\n",
      "17670/17670 - 1s - loss: 1.6665 - acc: 0.3968\n",
      "Epoch 40/100\n",
      "17670/17670 - 2s - loss: 1.6659 - acc: 0.3955\n",
      "Epoch 41/100\n",
      "17670/17670 - 1s - loss: 1.6661 - acc: 0.3988\n",
      "Epoch 42/100\n",
      "17670/17670 - 1s - loss: 1.6661 - acc: 0.3975\n",
      "Epoch 43/100\n",
      "17670/17670 - 1s - loss: 1.6655 - acc: 0.3962\n",
      "Epoch 44/100\n",
      "17670/17670 - 1s - loss: 1.6661 - acc: 0.3984\n",
      "Epoch 45/100\n",
      "17670/17670 - 1s - loss: 1.6661 - acc: 0.3997\n",
      "Epoch 46/100\n",
      "17670/17670 - 2s - loss: 1.6659 - acc: 0.3963\n",
      "Epoch 47/100\n",
      "17670/17670 - 1s - loss: 1.6658 - acc: 0.3977\n",
      "Epoch 48/100\n",
      "17670/17670 - 1s - loss: 1.6658 - acc: 0.3958\n",
      "Epoch 49/100\n",
      "17670/17670 - 1s - loss: 1.6657 - acc: 0.3988\n",
      "Epoch 50/100\n",
      "17670/17670 - 1s - loss: 1.6657 - acc: 0.3979\n",
      "Epoch 51/100\n",
      "17670/17670 - 1s - loss: 1.6656 - acc: 0.3975\n",
      "Epoch 52/100\n",
      "17670/17670 - 1s - loss: 1.6655 - acc: 0.3980\n",
      "Epoch 53/100\n",
      "17670/17670 - 1s - loss: 1.6654 - acc: 0.3977\n",
      "Epoch 54/100\n",
      "17670/17670 - 1s - loss: 1.6655 - acc: 0.3977\n",
      "Epoch 55/100\n",
      "17670/17670 - 1s - loss: 1.6652 - acc: 0.3974\n",
      "Epoch 56/100\n",
      "17670/17670 - 1s - loss: 1.6654 - acc: 0.3973\n",
      "Epoch 57/100\n",
      "17670/17670 - 1s - loss: 1.6655 - acc: 0.3978\n",
      "Epoch 58/100\n",
      "17670/17670 - 1s - loss: 1.6652 - acc: 0.3981\n",
      "Epoch 59/100\n",
      "17670/17670 - 1s - loss: 1.6652 - acc: 0.3975\n",
      "Epoch 60/100\n",
      "17670/17670 - 1s - loss: 1.6653 - acc: 0.3985\n",
      "Epoch 61/100\n",
      "17670/17670 - 1s - loss: 1.6649 - acc: 0.3967\n",
      "Epoch 62/100\n",
      "17670/17670 - 1s - loss: 1.6649 - acc: 0.3978\n",
      "Epoch 63/100\n",
      "17670/17670 - 1s - loss: 1.6650 - acc: 0.3969\n",
      "Epoch 64/100\n",
      "17670/17670 - 1s - loss: 1.6649 - acc: 0.3985\n",
      "Epoch 65/100\n",
      "17670/17670 - 1s - loss: 1.6647 - acc: 0.3976\n",
      "Epoch 66/100\n",
      "17670/17670 - 1s - loss: 1.6648 - acc: 0.3976\n",
      "Epoch 67/100\n",
      "17670/17670 - 1s - loss: 1.6645 - acc: 0.3979\n",
      "Epoch 68/100\n",
      "17670/17670 - 1s - loss: 1.6646 - acc: 0.3981\n",
      "Epoch 69/100\n",
      "17670/17670 - 1s - loss: 1.6641 - acc: 0.3969\n",
      "Epoch 70/100\n",
      "17670/17670 - 2s - loss: 1.6644 - acc: 0.3992\n",
      "Epoch 71/100\n",
      "17670/17670 - 1s - loss: 1.6642 - acc: 0.3965\n",
      "Epoch 72/100\n",
      "17670/17670 - 1s - loss: 1.6642 - acc: 0.3998\n",
      "Epoch 73/100\n",
      "17670/17670 - 1s - loss: 1.6642 - acc: 0.3972\n",
      "Epoch 74/100\n",
      "17670/17670 - 1s - loss: 1.6638 - acc: 0.3982\n",
      "Epoch 75/100\n",
      "17670/17670 - 1s - loss: 1.6639 - acc: 0.3973\n",
      "Epoch 76/100\n",
      "17670/17670 - 1s - loss: 1.6638 - acc: 0.3985\n",
      "Epoch 77/100\n",
      "17670/17670 - 1s - loss: 1.6636 - acc: 0.3997\n",
      "Epoch 78/100\n",
      "17670/17670 - 1s - loss: 1.6638 - acc: 0.3982\n",
      "Epoch 79/100\n",
      "17670/17670 - 1s - loss: 1.6637 - acc: 0.3980\n",
      "Epoch 80/100\n",
      "17670/17670 - 1s - loss: 1.6634 - acc: 0.3989\n",
      "Epoch 81/100\n",
      "17670/17670 - 2s - loss: 1.6638 - acc: 0.3979\n",
      "Epoch 82/100\n",
      "17670/17670 - 1s - loss: 1.6635 - acc: 0.3988\n",
      "Epoch 83/100\n",
      "17670/17670 - 1s - loss: 1.6632 - acc: 0.3993\n",
      "Epoch 84/100\n",
      "17670/17670 - 1s - loss: 1.6635 - acc: 0.3976\n",
      "Epoch 85/100\n",
      "17670/17670 - 1s - loss: 1.6631 - acc: 0.3982\n",
      "Epoch 86/100\n",
      "17670/17670 - 1s - loss: 1.6631 - acc: 0.3987\n",
      "Epoch 87/100\n",
      "17670/17670 - 1s - loss: 1.6631 - acc: 0.3999\n",
      "Epoch 88/100\n",
      "17670/17670 - 1s - loss: 1.6629 - acc: 0.3989\n",
      "Epoch 89/100\n",
      "17670/17670 - 1s - loss: 1.6628 - acc: 0.3987\n",
      "Epoch 90/100\n",
      "17670/17670 - 1s - loss: 1.6631 - acc: 0.3993\n",
      "Epoch 91/100\n",
      "17670/17670 - 1s - loss: 1.6628 - acc: 0.3967\n",
      "Epoch 92/100\n",
      "17670/17670 - 1s - loss: 1.6629 - acc: 0.3998\n",
      "Epoch 93/100\n",
      "17670/17670 - 1s - loss: 1.6627 - acc: 0.3988\n",
      "Epoch 94/100\n",
      "17670/17670 - 1s - loss: 1.6627 - acc: 0.3996\n",
      "Epoch 95/100\n",
      "17670/17670 - 1s - loss: 1.6626 - acc: 0.3978\n",
      "Epoch 96/100\n",
      "17670/17670 - 1s - loss: 1.6628 - acc: 0.3978\n",
      "Epoch 97/100\n",
      "17670/17670 - 1s - loss: 1.6625 - acc: 0.3975\n",
      "Epoch 98/100\n",
      "17670/17670 - 1s - loss: 1.6624 - acc: 0.3986\n",
      "Epoch 99/100\n",
      "17670/17670 - 1s - loss: 1.6623 - acc: 0.3984\n",
      "Epoch 100/100\n",
      "17670/17670 - 1s - loss: 1.6625 - acc: 0.3989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16d1d690b88>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\msflo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4075: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=20, activation='selu', input_dim=8)) #selu vs relu?\n",
    "deep_model.add(Dense(units=25, activation='selu'))\n",
    "deep_model.add(Dense(units=25, activation='selu'))\n",
    "deep_model.add(Dense(units=15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 25)                525       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 15)                390       \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17670/17670 - 1s - loss: 1.8873 - acc: 0.3544\n",
      "Epoch 2/100\n",
      "17670/17670 - 1s - loss: 1.7039 - acc: 0.3824\n",
      "Epoch 3/100\n",
      "17670/17670 - 1s - loss: 1.6850 - acc: 0.3886\n",
      "Epoch 4/100\n",
      "17670/17670 - 1s - loss: 1.6743 - acc: 0.3890\n",
      "Epoch 5/100\n",
      "17670/17670 - 1s - loss: 1.6643 - acc: 0.3930\n",
      "Epoch 6/100\n",
      "17670/17670 - 1s - loss: 1.6564 - acc: 0.3968\n",
      "Epoch 7/100\n",
      "17670/17670 - 1s - loss: 1.6494 - acc: 0.3993\n",
      "Epoch 8/100\n",
      "17670/17670 - 2s - loss: 1.6436 - acc: 0.3999\n",
      "Epoch 9/100\n",
      "17670/17670 - 2s - loss: 1.6397 - acc: 0.4001\n",
      "Epoch 10/100\n",
      "17670/17670 - 2s - loss: 1.6358 - acc: 0.4026\n",
      "Epoch 11/100\n",
      "17670/17670 - 2s - loss: 1.6320 - acc: 0.4062\n",
      "Epoch 12/100\n",
      "17670/17670 - 2s - loss: 1.6271 - acc: 0.4065\n",
      "Epoch 13/100\n",
      "17670/17670 - 2s - loss: 1.6246 - acc: 0.4097\n",
      "Epoch 14/100\n",
      "17670/17670 - 2s - loss: 1.6229 - acc: 0.4074\n",
      "Epoch 15/100\n",
      "17670/17670 - 1s - loss: 1.6197 - acc: 0.4073\n",
      "Epoch 16/100\n",
      "17670/17670 - 1s - loss: 1.6170 - acc: 0.4095\n",
      "Epoch 17/100\n",
      "17670/17670 - 1s - loss: 1.6154 - acc: 0.4123\n",
      "Epoch 18/100\n",
      "17670/17670 - 1s - loss: 1.6118 - acc: 0.4117\n",
      "Epoch 19/100\n",
      "17670/17670 - 2s - loss: 1.6115 - acc: 0.4156\n",
      "Epoch 20/100\n",
      "17670/17670 - 1s - loss: 1.6103 - acc: 0.4117\n",
      "Epoch 21/100\n",
      "17670/17670 - 1s - loss: 1.6087 - acc: 0.4140\n",
      "Epoch 22/100\n",
      "17670/17670 - 2s - loss: 1.6054 - acc: 0.4148\n",
      "Epoch 23/100\n",
      "17670/17670 - 1s - loss: 1.6035 - acc: 0.4161\n",
      "Epoch 24/100\n",
      "17670/17670 - 1s - loss: 1.6020 - acc: 0.4150\n",
      "Epoch 25/100\n",
      "17670/17670 - 1s - loss: 1.6014 - acc: 0.4151\n",
      "Epoch 26/100\n",
      "17670/17670 - 1s - loss: 1.6003 - acc: 0.4146\n",
      "Epoch 27/100\n",
      "17670/17670 - 1s - loss: 1.5982 - acc: 0.4157\n",
      "Epoch 28/100\n",
      "17670/17670 - 1s - loss: 1.5978 - acc: 0.4158\n",
      "Epoch 29/100\n",
      "17670/17670 - 1s - loss: 1.5953 - acc: 0.4185\n",
      "Epoch 30/100\n",
      "17670/17670 - 2s - loss: 1.5959 - acc: 0.4165\n",
      "Epoch 31/100\n",
      "17670/17670 - 2s - loss: 1.5943 - acc: 0.4174\n",
      "Epoch 32/100\n",
      "17670/17670 - 1s - loss: 1.5929 - acc: 0.4164\n",
      "Epoch 33/100\n",
      "17670/17670 - 1s - loss: 1.5925 - acc: 0.4160\n",
      "Epoch 34/100\n",
      "17670/17670 - 1s - loss: 1.5899 - acc: 0.4200\n",
      "Epoch 35/100\n",
      "17670/17670 - 1s - loss: 1.5881 - acc: 0.4196\n",
      "Epoch 36/100\n",
      "17670/17670 - 1s - loss: 1.5872 - acc: 0.4199\n",
      "Epoch 37/100\n",
      "17670/17670 - 1s - loss: 1.5865 - acc: 0.4199\n",
      "Epoch 38/100\n",
      "17670/17670 - 1s - loss: 1.5859 - acc: 0.4168\n",
      "Epoch 39/100\n",
      "17670/17670 - 1s - loss: 1.5848 - acc: 0.4189\n",
      "Epoch 40/100\n",
      "17670/17670 - 1s - loss: 1.5856 - acc: 0.4198\n",
      "Epoch 41/100\n",
      "17670/17670 - 2s - loss: 1.5840 - acc: 0.4204\n",
      "Epoch 42/100\n",
      "17670/17670 - 1s - loss: 1.5840 - acc: 0.4161\n",
      "Epoch 43/100\n",
      "17670/17670 - 1s - loss: 1.5831 - acc: 0.4195\n",
      "Epoch 44/100\n",
      "17670/17670 - 1s - loss: 1.5816 - acc: 0.4184\n",
      "Epoch 45/100\n",
      "17670/17670 - 1s - loss: 1.5819 - acc: 0.4226\n",
      "Epoch 46/100\n",
      "17670/17670 - 1s - loss: 1.5817 - acc: 0.4204\n",
      "Epoch 47/100\n",
      "17670/17670 - 1s - loss: 1.5802 - acc: 0.4208\n",
      "Epoch 48/100\n",
      "17670/17670 - 1s - loss: 1.5805 - acc: 0.4214\n",
      "Epoch 49/100\n",
      "17670/17670 - 1s - loss: 1.5790 - acc: 0.4185\n",
      "Epoch 50/100\n",
      "17670/17670 - 1s - loss: 1.5774 - acc: 0.4214\n",
      "Epoch 51/100\n",
      "17670/17670 - 2s - loss: 1.5771 - acc: 0.4236\n",
      "Epoch 52/100\n",
      "17670/17670 - 2s - loss: 1.5764 - acc: 0.4203\n",
      "Epoch 53/100\n",
      "17670/17670 - 1s - loss: 1.5761 - acc: 0.4224\n",
      "Epoch 54/100\n",
      "17670/17670 - 1s - loss: 1.5755 - acc: 0.4213\n",
      "Epoch 55/100\n",
      "17670/17670 - 1s - loss: 1.5762 - acc: 0.4217\n",
      "Epoch 56/100\n",
      "17670/17670 - 2s - loss: 1.5751 - acc: 0.4234\n",
      "Epoch 57/100\n",
      "17670/17670 - 2s - loss: 1.5745 - acc: 0.4229\n",
      "Epoch 58/100\n",
      "17670/17670 - 2s - loss: 1.5736 - acc: 0.4236\n",
      "Epoch 59/100\n",
      "17670/17670 - 1s - loss: 1.5740 - acc: 0.4251\n",
      "Epoch 60/100\n",
      "17670/17670 - 1s - loss: 1.5744 - acc: 0.4212\n",
      "Epoch 61/100\n",
      "17670/17670 - 1s - loss: 1.5734 - acc: 0.4236\n",
      "Epoch 62/100\n",
      "17670/17670 - 1s - loss: 1.5728 - acc: 0.4237\n",
      "Epoch 63/100\n",
      "17670/17670 - 1s - loss: 1.5728 - acc: 0.4238\n",
      "Epoch 64/100\n",
      "17670/17670 - 1s - loss: 1.5704 - acc: 0.4232\n",
      "Epoch 65/100\n",
      "17670/17670 - 1s - loss: 1.5703 - acc: 0.4237\n",
      "Epoch 66/100\n",
      "17670/17670 - 1s - loss: 1.5723 - acc: 0.4229\n",
      "Epoch 67/100\n",
      "17670/17670 - 1s - loss: 1.5698 - acc: 0.4267\n",
      "Epoch 68/100\n",
      "17670/17670 - 2s - loss: 1.5705 - acc: 0.4246\n",
      "Epoch 69/100\n",
      "17670/17670 - 1s - loss: 1.5694 - acc: 0.4251\n",
      "Epoch 70/100\n",
      "17670/17670 - 1s - loss: 1.5679 - acc: 0.4277\n",
      "Epoch 71/100\n",
      "17670/17670 - 1s - loss: 1.5691 - acc: 0.4243\n",
      "Epoch 72/100\n",
      "17670/17670 - 1s - loss: 1.5677 - acc: 0.4255\n",
      "Epoch 73/100\n",
      "17670/17670 - 1s - loss: 1.5666 - acc: 0.4266\n",
      "Epoch 74/100\n",
      "17670/17670 - 1s - loss: 1.5671 - acc: 0.4259\n",
      "Epoch 75/100\n",
      "17670/17670 - 1s - loss: 1.5674 - acc: 0.4277\n",
      "Epoch 76/100\n",
      "17670/17670 - 1s - loss: 1.5673 - acc: 0.4259\n",
      "Epoch 77/100\n",
      "17670/17670 - 1s - loss: 1.5670 - acc: 0.4275\n",
      "Epoch 78/100\n",
      "17670/17670 - 1s - loss: 1.5663 - acc: 0.4276\n",
      "Epoch 79/100\n",
      "17670/17670 - 1s - loss: 1.5660 - acc: 0.4295\n",
      "Epoch 80/100\n",
      "17670/17670 - 1s - loss: 1.5659 - acc: 0.4268\n",
      "Epoch 81/100\n",
      "17670/17670 - 1s - loss: 1.5651 - acc: 0.4271\n",
      "Epoch 82/100\n",
      "17670/17670 - 1s - loss: 1.5636 - acc: 0.4272\n",
      "Epoch 83/100\n",
      "17670/17670 - 1s - loss: 1.5658 - acc: 0.4270\n",
      "Epoch 84/100\n",
      "17670/17670 - 1s - loss: 1.5637 - acc: 0.4281\n",
      "Epoch 85/100\n",
      "17670/17670 - 1s - loss: 1.5649 - acc: 0.4253\n",
      "Epoch 86/100\n",
      "17670/17670 - 1s - loss: 1.5634 - acc: 0.4273\n",
      "Epoch 87/100\n",
      "17670/17670 - 1s - loss: 1.5637 - acc: 0.4255\n",
      "Epoch 88/100\n",
      "17670/17670 - 1s - loss: 1.5634 - acc: 0.4272\n",
      "Epoch 89/100\n",
      "17670/17670 - 1s - loss: 1.5636 - acc: 0.4267\n",
      "Epoch 90/100\n",
      "17670/17670 - 2s - loss: 1.5631 - acc: 0.4265\n",
      "Epoch 91/100\n",
      "17670/17670 - 1s - loss: 1.5636 - acc: 0.4282\n",
      "Epoch 92/100\n",
      "17670/17670 - 1s - loss: 1.5603 - acc: 0.4286\n",
      "Epoch 93/100\n",
      "17670/17670 - 2s - loss: 1.5624 - acc: 0.4276\n",
      "Epoch 94/100\n",
      "17670/17670 - 1s - loss: 1.5616 - acc: 0.4261\n",
      "Epoch 95/100\n",
      "17670/17670 - 1s - loss: 1.5608 - acc: 0.4259\n",
      "Epoch 96/100\n",
      "17670/17670 - 1s - loss: 1.5612 - acc: 0.4274\n",
      "Epoch 97/100\n",
      "17670/17670 - 1s - loss: 1.5603 - acc: 0.4282\n",
      "Epoch 98/100\n",
      "17670/17670 - 1s - loss: 1.5595 - acc: 0.4288\n",
      "Epoch 99/100\n",
      "17670/17670 - 2s - loss: 1.5596 - acc: 0.4278\n",
      "Epoch 100/100\n",
      "17670/17670 - 2s - loss: 1.5599 - acc: 0.4310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16d239d7e08>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
